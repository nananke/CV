{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLCS hw1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nananke/CV/blob/gh-pages/MLCS_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXOPYustD5FX"
      },
      "source": [
        "#Name:Kenan Xu\n",
        "#netID:kx2015\n",
        "\n",
        "#step 1 Download the ling-spam dataset from http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
        "#Please use the “lingspam_public01” corpus with both lemmatization and stop-word enabled (under\n",
        "#the lemm_stop folder).\n",
        "\n",
        "#uncommet to download dataset\n",
        "#!wget http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
        "#!tar xvzf lingspam_public.tar.gz\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsj5wNMwES4U",
        "outputId": "1eec424b-5c14-4620-9bc7-8ef6a976b296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#data extraction\n",
        "import glob\n",
        "import numpy as np\n",
        "from math import log2\n",
        "#create a 3-d array, d1 = part_num, d2 = file name, d3 = text content\n",
        "\n",
        "training_dataset = []\n",
        "testing_dataset = []\n",
        "word_total = []\n",
        "spam_count = 0\n",
        "legit_count = 0\n",
        "for n in range(1,10):\n",
        "  subpart = \"part\"+str(n)\n",
        "  print(subpart)\n",
        "  for file in glob.glob(\"lingspam_public/lemm_stop/\"+subpart+\"/*.txt\"):\n",
        "    f = open(file, \"r\")\n",
        "    d = []\n",
        "    for word in f.read().split():\n",
        "       #print(word)      \n",
        "       d.append(word)\n",
        "    word_total.append(d)\n",
        "\n",
        "    arr = np.append([n],[file])\n",
        "    f = open(file, \"r\")\n",
        "    final_arr = np.append([arr],[f.read()])\n",
        "    \n",
        "   \n",
        "    fullstring = file\n",
        "    substring = \"spm\"\n",
        "    if substring in fullstring:\n",
        "     spam_count = spam_count + 1\n",
        "     labeled_final_arr_0 = np.append([final_arr],1)\n",
        "     training_dataset.append(labeled_final_arr_0)\n",
        "    else:\n",
        "     legit_count = legit_count + 1\n",
        "     labeled_final_arr_1 = np.append([final_arr],0)\n",
        "     training_dataset.append(labeled_final_arr_1)\n",
        "\n",
        "for n in range(10,11):\n",
        "  subpart = \"part\"+str(n)\n",
        "  print(subpart)\n",
        "  for file in glob.glob(\"lingspam_public/lemm_stop/\"+subpart+\"/*.txt\"):\n",
        "    f = open(file, \"r\")\n",
        "    arr = np.append([n],[file])\n",
        "    final_arr = np.append([arr],[f.read()])\n",
        "  \n",
        "\n",
        "     \n",
        "    fullstring = file\n",
        "    substring = \"spm\"\n",
        "    if substring in fullstring:\n",
        "     test_labeled_final_arr_0 = np.append([final_arr],1)\n",
        "     testing_dataset.append(test_labeled_final_arr_0)\n",
        "    else:\n",
        "     test_labeled_final_arr_1 = np.append([final_arr],0)\n",
        "     testing_dataset.append(test_labeled_final_arr_1)\n",
        "\n",
        "print(\"total spam email number in training:\",spam_count,\"total legit email number in training\", legit_count)\n",
        "print(\"total training email number:\",len(training_dataset),\"total testing email number:\",len(testing_dataset))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class0 = spam_count/(len(training_dataset))\n",
        "class1 = legit_count/(len(training_dataset))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "part1\n",
            "part2\n",
            "part3\n",
            "part4\n",
            "part5\n",
            "part6\n",
            "part7\n",
            "part8\n",
            "part9\n",
            "part10\n",
            "total spam email number in training: 432 total legit email number in training 2170\n",
            "total training email number: 2602 total testing email number: 291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTsI3z905JFn",
        "outputId": "a43a5a9e-e727-4f40-c533-ba4ceb06c76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "#information gain calculation\n",
        "\n",
        "unique_total_word = []\n",
        "for x in range(0,len(word_total)):\n",
        "  for y in range(0,len(word_total[x])):\n",
        "    unique_total_word.append(word_total[x][y])\n",
        "\n",
        "#delete the duplicate one for the total word array in order to decease the running time\n",
        "unique_total_word = list(dict.fromkeys(unique_total_word))\n",
        "unique_total_word.remove(\"!\")\n",
        "#array to save info gain result\n",
        "gain_result = []\n",
        "#entropy before the given word \n",
        "hc = -(class0 * log2(class0) + class1 * log2(class1))\n",
        "#print(hc)\n",
        "\n",
        "for y in range (0, len(unique_total_word)):\n",
        "  #print(\"processing: \",y,\"/\",len(unique_total_word))\n",
        "  #legit word appear\n",
        "  lwa =0  \n",
        "  #legit word not appear\n",
        "  lwna =0\n",
        "  #spam word appear\n",
        "  swa =0\n",
        "  #spam word not appear\n",
        "  swna =0\n",
        "\n",
        "  for x in range(0,len(training_dataset)):\n",
        "   #split sentence into bag of words first, then do the comparsion\n",
        "   words = training_dataset[x][2].split()\n",
        "   if unique_total_word[y] in words:\n",
        "    if training_dataset[x][3] == '1':\n",
        "     swa = swa + 1\n",
        "     #print('found in spam: ',training_dataset[x][3])\n",
        "    else :\n",
        "      lwa = lwa + 1  \n",
        "      #print('found in legit',training_dataset[x][3])\n",
        "\n",
        "  lwna = 2170 - lwa\n",
        "  swna = 432 - swa\n",
        "  #print(lwa,lwna,swa,swna)\n",
        "  \n",
        "  try:\n",
        "    entropy1 = -((lwa)/(lwa+swa) * log2((lwa)/(lwa+swa)) + (swa)/(lwa+swa) * log2((swa)/(lwa+swa)))\n",
        "    entropy2 = -((lwna)/(lwna+swna) * log2((lwna)/(lwna+swna)) + (swna)/(lwna+swna) * log2((swna)/(lwna+swna)))\n",
        "  except:\n",
        "    #since there are some word with P = 0, using Laplace smoothing to ensure there will be no math error\n",
        "    entropy1 = -((lwa+1)/(lwa+swa+2) * log2((lwa+1)/(lwa+swa+2)) + (swa+1)/(lwa+swa+2) * log2((swa+1)/(lwa+swa+2)))\n",
        "    entropy2 = -((lwna+1)/(lwna+swna+2) * log2((lwna+1)/(lwna+swna+2)) + (swna+1)/(lwna+swna+2) * log2((swna+1)/(lwna+swna+2)))\n",
        "\n",
        "  #H(c|x)\n",
        "  hcx =  (lwa+swa)/len(training_dataset)*entropy1 + (lwna+swna)/len(training_dataset)*entropy2 \n",
        "\n",
        "  #IG = h(c) - h(c|x)\n",
        "  info_gain = hc - hcx\n",
        "  m = np.append([info_gain],[unique_total_word[y]])\n",
        "  gain_result.append(m)\n",
        "  #print(gain_result,\" \", unique_total_word[y])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9707d5018994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m    \u001b[0;31m#split sentence into bag of words first, then do the comparsion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m    \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0munique_total_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRrz7JjNP7Hk"
      },
      "source": [
        "#saving gain_result to local\n",
        "'''\n",
        "with open('your_file.txt', 'w') as f:\n",
        "    for item in gain_result:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z82ic6W8F3GL"
      },
      "source": [
        "#once we have calculate the IG, we can just upload txt from our local file since it takes long time to re-calculate\n",
        "'''\n",
        "gain_result=[]\n",
        "import re\n",
        "f = open(\"your_file.txt\", \"r\")\n",
        "for x in f:\n",
        "  extract = re.findall(r\"'(.*?)'\", x, re.DOTALL)\n",
        "  try:\n",
        "   #print(extract[1])\n",
        "   gain_result.append(extract)\n",
        "  except:\n",
        "    None\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7jkf2dpdLCv",
        "outputId": "5caae063-c026-493b-97c0-40f5d264c350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "print('TOP 10 Feature words List')\n",
        "\n",
        "for x in range(0,len(gain_result)):\n",
        "  gain_result[x][0] = '{:.5f}'.format(float(gain_result[x][0]))\n",
        "gain_result.sort(reverse=False,key=lambda x: x[0]) \n",
        "for x in range(len(gain_result)-10,len(gain_result)):\n",
        "  print(gain_result[x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOP 10 Feature words List\n",
            "['0.08879' 'our']\n",
            "['0.09251' 'market']\n",
            "['0.09418' '@']\n",
            "['0.10117' 'click']\n",
            "['0.11868' 'money']\n",
            "['0.14501' 'university']\n",
            "['0.14515' 'linguistic']\n",
            "['0.16573' 'free']\n",
            "['0.16891' 'remove']\n",
            "['0.20444' 'language']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExZ09nTmfXG1"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "#first top 10,100,1000 features with BernoulliNB\n",
        "feature_10 = []\n",
        "feature_100 = []\n",
        "feature_1000 = []\n",
        "for x in range(len(gain_result)-10,len(gain_result)):\n",
        "  #print(gain_result[x])\n",
        "  feature_10.append(gain_result[x][1])\n",
        "\n",
        "for x in range(len(gain_result)-100,len(gain_result)):\n",
        "  #print(gain_result[x])\n",
        "  feature_100.append(gain_result[x][1])\n",
        "\n",
        "for x in range(len(gain_result)-1000,len(gain_result)):\n",
        "  #print(gain_result[x])\n",
        "  feature_1000.append(gain_result[x][1])\n",
        "\n",
        "feature_array = [feature_10,feature_100,feature_1000]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npUklmIT0w75",
        "outputId": "7aa82ba0-2791-457e-9d6c-f277781f39b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\n",
        "#Bernoulli NB classifier with binary features\n",
        "#for each file in training text, feature is found =1, feature not found =0\n",
        "for m in range (0, 3):\n",
        " X_train =[]\n",
        " y_train =[]\n",
        " X_test = []\n",
        " y_test = []\n",
        " for x in range(0,len(training_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_train.append(int(training_dataset[x][3]))\n",
        "   wordsbag = training_dataset[x][2].split()\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "     if feature_array[m][y] in wordsbag:\n",
        "       row[y] = 1 \n",
        "   X_train.append(row)\n",
        " \n",
        " #for each file in training text, feature is found =1, feature not found =0\n",
        " for x in range(0,len(testing_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_test.append(int(testing_dataset[x][3]))\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "     if feature_array[m][y] in testing_dataset[x][2]:\n",
        "       row[y] = 1 \n",
        "   X_test.append(row)\n",
        "   \n",
        "\n",
        " from sklearn.naive_bayes import BernoulliNB\n",
        " from sklearn.model_selection import train_test_split\n",
        " from sklearn import metrics\n",
        " from sklearn.metrics import confusion_matrix\n",
        " # Create three binary features\n",
        " X = X_train\n",
        " # Create a binary target vector\n",
        " y = y_train\n",
        " # View first ten observations\n",
        " \n",
        " # Create Bernoulli Naive Bayes object with prior probabilities of each class\n",
        " clf = BernoulliNB(class_prior=[0.25, 0.5])\n",
        " \n",
        " # Train model\n",
        " model = clf.fit(X, y)\n",
        " #print(len(clf.predict(X_test)))\n",
        " #print(len(y_test))\n",
        " tn, fp, fn, tp = confusion_matrix(y_test,model.predict(X_test)).ravel()\n",
        " print('NB classifier with binary features',len(feature_array[m]),'features ','Spam precision:',tn/(tn+fn))\n",
        " print('NB classifier with binary features',len(feature_array[m]),'features ','Spam recall',clf.score(X_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB classifier with binary features 10 features  Spam precision: 0.9869565217391304\n",
            "NB classifier with binary features 10 features  Spam recall 0.9381443298969072\n",
            "NB classifier with binary features 100 features  Spam precision: 0.9714285714285714\n",
            "NB classifier with binary features 100 features  Spam recall 0.9621993127147767\n",
            "NB classifier with binary features 1000 features  Spam precision: 0.9444444444444444\n",
            "NB classifier with binary features 1000 features  Spam recall 0.9381443298969072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwn23drTaK-O",
        "outputId": "ffe4bdc0-ce76-4888-e446-e3eac3d460b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#Multinomial NB with binary features;\n",
        "#Multi NB shares the feature training data with Ber NB since they all needs binary data \n",
        "#for each file in training text, feature is found =1, feature not found =0\n",
        "#for each file in training text, feature is found =1, feature not found =0\n",
        "for m in range (0, 3):\n",
        " X_train =[]\n",
        " y_train =[]\n",
        " X_test = []\n",
        " y_test = []\n",
        " for x in range(0,len(training_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_train.append(int(training_dataset[x][3]))\n",
        "   wordsbag = training_dataset[x][2].split()\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "     if feature_array[m][y] in wordsbag:\n",
        "       row[y] = 1 \n",
        "   X_train.append(row)\n",
        " \n",
        " #for each file in training text, feature is found =1, feature not found =0\n",
        " for x in range(0,len(testing_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_test.append(int(testing_dataset[x][3]))\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "     if feature_array[m][y] in testing_dataset[x][2]:\n",
        "       row[y] = 1 \n",
        "   X_test.append(row)\n",
        "   \n",
        "\n",
        " \n",
        " from sklearn.naive_bayes import MultinomialNB \n",
        " # Create three binary features\n",
        " X = X_train\n",
        " # Create a binary target vector\n",
        " y = y_train\n",
        " # View first ten observations\n",
        " \n",
        " # Create Bernoulli Naive Bayes object with prior probabilities of each class\n",
        " clf = MultinomialNB()\n",
        " \n",
        " # Train model\n",
        " model = clf.fit(X, y)\n",
        " #print(len(clf.predict(X_test)))\n",
        " #print(len(y_test))\n",
        " tn, fp, fn, tp = confusion_matrix(y_test,model.predict(X_test)).ravel()\n",
        " print('Multinomial NB with binary features',len(feature_array[m]),'features ','Spam precision:',tn/(tn+fn))\n",
        " print('Multinomial NB with binary features',len(feature_array[m]),'features ','Spam recall',clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial NB with binary features 10 features  Spam precision: 0.9598393574297188\n",
            "Multinomial NB with binary features 10 features  Spam recall 0.9553264604810997\n",
            "Multinomial NB with binary features 100 features  Spam precision: 0.9836734693877551\n",
            "Multinomial NB with binary features 100 features  Spam recall 0.9828178694158075\n",
            "Multinomial NB with binary features 1000 features  Spam precision: 0.9758064516129032\n",
            "Multinomial NB with binary features 1000 features  Spam recall 0.979381443298969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL8Q_ux5bmiw",
        "outputId": "9706f360-496b-4b08-cdba-d254f8ba4d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#Multi TF, we need to re-caculate training data to count for how many times feature words appear\n",
        "for m in range (0, 3):\n",
        " X_train =[]\n",
        " y_train =[]\n",
        " X_test = []\n",
        " y_test = []\n",
        " for x in range(0,len(training_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_train.append(int(training_dataset[x][3]))\n",
        "   wordsbag = training_dataset[x][2].split()\n",
        "   for y in range (0,len(feature_array[m])):          \n",
        "       count = wordsbag.count(feature_array[m][y])\n",
        "       row[y] = count \n",
        "   X_train.append(row)\n",
        "\n",
        "\n",
        "  \n",
        " \n",
        " #for each file in training text, feature is found =1, feature not found =0\n",
        " for x in range(0,len(testing_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_test.append(int(testing_dataset[x][3]))\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "       count = testing_dataset[x][2].count(feature_array[m][y])\n",
        "       row[y] = count \n",
        "   X_test.append(row)\n",
        " \n",
        "\n",
        " from sklearn.naive_bayes import MultinomialNB \n",
        "\n",
        " # Create three binary features\n",
        " X = X_train\n",
        " # Create a binary target vector\n",
        " y = y_train\n",
        " # View first ten observations\n",
        " \n",
        " # Create Bernoulli Naive Bayes object with prior probabilities of each class\n",
        " clf = MultinomialNB()\n",
        " # Train model\n",
        " model = clf.fit(X, y)\n",
        " #print(len(clf.predict(X_test)))\n",
        " #print(len(y_test))\n",
        "\n",
        " tn, fp, fn, tp = confusion_matrix(y_test,model.predict(X_test)).ravel()\n",
        " print('Multi TF:',len(feature_array[m]),'features ','Spam precision:',tn/(tn+fn))\n",
        " print('Multi TF:',len(feature_array[m]),'features ','Spam recall',clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multi TF: 10 features  Spam precision: 0.9871794871794872\n",
            "Multi TF: 10 features  Spam recall 0.9518900343642611\n",
            "Multi TF: 100 features  Spam precision: 0.9795918367346939\n",
            "Multi TF: 100 features  Spam recall 0.9759450171821306\n",
            "Multi TF: 1000 features  Spam precision: 0.8515901060070671\n",
            "Multi TF: 1000 features  Spam recall 0.852233676975945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtd76QvxxaIR",
        "outputId": "900b3206-a7f5-419b-bba6-eb589603b185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#SVM based spam filter\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "for m in range (0, 3):\n",
        " X_train =[]\n",
        " y_train =[]\n",
        " for x in range(0,len(training_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_train.append(int(training_dataset[x][3]))\n",
        "   wordsbag = training_dataset[x][2].split()\n",
        "   for y in range (0,len(feature_array[m])):          \n",
        "       count = wordsbag.count(feature_array[m][y])\n",
        "       row[y] = count \n",
        "   X_train.append(row)\n",
        "\n",
        " X_test = []\n",
        " y_test = []\n",
        "  \n",
        " \n",
        " #for each file in training text, feature is found =1, feature not found =0\n",
        " for x in range(0,len(testing_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_test.append(int(testing_dataset[x][3]))\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "       count = testing_dataset[x][2].count(feature_array[m][y])\n",
        "       row[y] = count \n",
        "   X_test.append(row)\n",
        "\n",
        " X = X_train\n",
        " y = y_train\n",
        " from sklearn.svm import SVC\n",
        " from sklearn.model_selection import GridSearchCV\n",
        " \n",
        " #cross-validation on the training dataset.\n",
        " gamma = []\n",
        " i = 0.0001\n",
        " while i > 0.000000001:\n",
        "  gamma.append(i) \n",
        "  i = i / 10\n",
        " param_grid = [\n",
        "  {'C': [0.1, 1000, 10000,100000], 'kernel': ['linear']},\n",
        "  {'C': [0.1, 1000, 10000,100000], 'gamma': gamma, 'kernel': ['rbf']},\n",
        "  ]\n",
        " clf = GridSearchCV(SVC(), param_grid, cv=3, refit=True, verbose=100,return_train_score = True)\n",
        " clf.fit(X, y)\n",
        "\n",
        " from sklearn.metrics import accuracy_score\n",
        " print(clf.best_params_)\n",
        " y_pred = clf.predict(X_test)\n",
        " accuracy_score(y_pred, y_test)\n",
        " tn, fp, fn, tp = confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
        " print(len(feature_array[m]),'features ','Spam precision:',tn/(tn+fn))\n",
        " print(len(feature_array[m]),'features ','Spam recall',clf.score(X_test, y_test))\n",
        " #feature 10\n",
        " #{'C': 100000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
        " #10 features  Spam precision: 0.8222222222222222\n",
        " #10 features  Spam recall 0.9312714776632303\n",
        "\n",
        " #feature100\n",
        " #{'C': 0.1, 'kernel': 'linear'}\n",
        " #100 features  Spam precision: 0.7\n",
        " #100 features  Spam recall 0.9140893470790378\n",
        "\n",
        " #feature1000\n",
        " #{'C': 100000, 'gamma': 1.0000000000000002e-07, 'kernel': 'rbf'}\n",
        " #1000 features  Spam precision: 1.0\n",
        " #1000 features  Spam recall 0.8625429553264605"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.962, test=0.960), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.957, test=0.957), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.963, test=0.947), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=0.971, test=0.956), total=   1.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.0s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=0.960, test=0.961), total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=0.970, test=0.961), total=   0.7s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    3.1s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=0.971, test=0.956), total=  10.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.1s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=0.961, test=0.965), total=  17.8s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   30.9s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=0.970, test=0.961), total=   8.2s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   39.1s remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=0.971, test=0.956), total= 1.5min\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.1min remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=0.960, test=0.961), total= 2.2min\n",
            "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  4.3min remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=0.970, test=0.961), total= 1.2min\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=0.965, test=0.959), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=0.963, test=0.963), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=0.968, test=0.957), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.956, test=0.957), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.949, test=0.948), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.956, test=0.942), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.915, test=0.911), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.907, test=0.909), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.912, test=0.905), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.863, test=0.859), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.861, test=0.862), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.856, test=0.862), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=0.971, test=0.956), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=0.965, test=0.963), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=0.969, test=0.962), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=0.966, test=0.960), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=0.961, test=0.958), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=0.968, test=0.957), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.956, test=0.956), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.949, test=0.946), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.956, test=0.943), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.915, test=0.911), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.905, test=0.909), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.912, test=0.905), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.863, test=0.859), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.861, test=0.862), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.856, test=0.863), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=0.973, test=0.964), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=0.967, test=0.967), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=0.971, test=0.960), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:  5.6min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=0.971, test=0.957), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=0.963, test=0.960), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=0.969, test=0.962), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.966, test=0.960), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.961, test=0.957), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.967, test=0.957), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.955, test=0.955), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.949, test=0.948), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.949, test=0.942), total=   0.0s\n",
            "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.916, test=0.916), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.905, test=0.909), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.916, test=0.909), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.863, test=0.859), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.860, test=0.862), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:  5.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.856, test=0.862), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:  5.7min remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:  5.7min finished\n",
            "{'C': 100000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "10 features  Spam precision: 0.9512195121951219\n",
            "10 features  Spam recall 0.9312714776632303\n",
            "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.993, test=0.980), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.991, test=0.979), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.991, test=0.980), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=0.999, test=0.975), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=1.000, test=0.979), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=0.999, test=0.976), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.9s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=0.999, test=0.975), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.2s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=1.000, test=0.979), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.4s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=0.999, test=0.976), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.4s remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=0.999, test=0.975), total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.9s remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=1.000, test=0.979), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    2.1s remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=0.999, test=0.976), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    2.2s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.841, test=0.842), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    2.7s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.847, test=0.843), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    3.2s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.845, test=0.847), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    3.7s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    4.2s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    4.7s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    5.2s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    5.8s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    6.3s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    6.8s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    7.3s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    7.8s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    8.3s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    8.8s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    9.3s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    9.8s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   10.2s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   10.7s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   11.2s remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=0.995, test=0.971), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   11.4s remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=0.994, test=0.977), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   11.5s remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=0.995, test=0.978), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   11.7s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.983, test=0.980), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   11.9s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.984, test=0.977), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   12.1s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.987, test=0.973), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   12.3s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.950, test=0.949), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:   12.6s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.945, test=0.941), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:   12.9s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.951, test=0.933), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   13.3s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.892, test=0.889), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   13.7s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.885, test=0.892), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:   14.1s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.895, test=0.885), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:   14.5s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.852, test=0.850), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   15.0s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.851, test=0.852), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:   15.4s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.855, test=0.850), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   15.9s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.835, test=0.834), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:   16.4s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.836), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:   16.9s remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.836, test=0.835), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   17.5s remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=0.998, test=0.971), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   17.6s remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=0.999, test=0.980), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   17.7s remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=0.999, test=0.977), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:   17.9s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=0.995, test=0.971), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:   18.0s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=0.994, test=0.984), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:   18.2s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=0.994, test=0.982), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:   18.3s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.983, test=0.983), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:   18.5s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.984, test=0.977), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:   18.7s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.986, test=0.973), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:   18.9s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.951, test=0.950), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:   19.2s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.945, test=0.943), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:   19.6s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.950, test=0.933), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   19.9s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.886, test=0.889), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:   20.3s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.885, test=0.892), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:   20.7s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.892, test=0.882), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:   21.1s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.852, test=0.850), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:   21.6s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.851, test=0.852), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:   22.1s remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.855, test=0.850), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:   22.6s remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=0.999, test=0.967), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:   22.7s remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.977), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:   22.8s remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=0.999, test=0.973), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:   23.0s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=0.998, test=0.970), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:   23.1s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=0.999, test=0.986), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:   23.2s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=0.998, test=0.980), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:   23.4s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.994, test=0.974), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:   23.5s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.994, test=0.977), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:   23.7s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.993, test=0.980), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:   23.8s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.983, test=0.985), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:   24.0s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.983, test=0.976), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:   24.2s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.987, test=0.972), total=   0.1s\n",
            "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:   24.4s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.950, test=0.949), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:   24.8s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.945, test=0.941), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   25.1s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.948, test=0.931), total=   0.2s\n",
            "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:   25.4s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.893, test=0.891), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:   25.8s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.884, test=0.889), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:   26.2s remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.888, test=0.881), total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:   26.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:   26.6s finished\n",
            "{'C': 0.1, 'kernel': 'linear'}\n",
            "100 features  Spam precision: 0.9696969696969697\n",
            "100 features  Spam recall 0.9140893470790378\n",
            "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=1.000, test=0.978), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.999, test=0.992), total=   1.1s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.0s remaining:    0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=1.000, test=0.987), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.4s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=1.000, test=0.975), total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.7s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=1.000, test=0.991), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.1s remaining:    0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV]  C=1000, kernel=linear, score=(train=1.000, test=0.983), total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    8.3s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=1.000, test=0.975), total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.6s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=1.000, test=0.991), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   11.0s remaining:    0.0s\n",
            "[CV] C=10000, kernel=linear ..........................................\n",
            "[CV]  C=10000, kernel=linear, score=(train=1.000, test=0.983), total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   12.2s remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=1.000, test=0.975), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.5s remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=1.000, test=0.991), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   14.9s remaining:    0.0s\n",
            "[CV] C=100000, kernel=linear .........................................\n",
            "[CV]  C=100000, kernel=linear, score=(train=1.000, test=0.983), total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   16.1s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.839, test=0.834), total=   2.8s\n",
            "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   20.7s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.847, test=0.844), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   25.4s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=(train=0.843, test=0.839), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   30.0s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.851, test=0.851), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   34.6s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.855, test=0.849), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   39.1s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1e-05, kernel=rbf ..................................\n",
            "[CV]  C=0.1, gamma=1e-05, kernel=rbf, score=(train=0.852, test=0.856), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   43.8s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.834, test=0.834), total=   3.0s\n",
            "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   48.5s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.839, test=0.835), total=   3.0s\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   53.1s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-06, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.834, test=0.834), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   57.8s remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   3.1s\n",
            "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-07, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.834, test=0.834), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000002e-08, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.834, test=0.834), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.5min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   2.6s\n",
            "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.6min remaining:    0.0s\n",
            "[CV] C=0.1, gamma=1.0000000000000003e-09, kernel=rbf .................\n",
            "[CV]  C=0.1, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.834, test=0.834), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.6min remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.971), total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.7min remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.953), total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  1.7min remaining:    0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.976), total=   1.5s\n",
            "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.7min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.997, test=0.983), total=   1.2s\n",
            "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  1.8min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.995, test=0.983), total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.8min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
            "[CV]  C=1000, gamma=1e-05, kernel=rbf, score=(train=0.996, test=0.986), total=   1.2s\n",
            "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.8min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.967, test=0.960), total=   1.6s\n",
            "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  1.9min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.961, test=0.958), total=   1.7s\n",
            "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  1.9min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-06, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.969, test=0.945), total=   1.6s\n",
            "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  2.0min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.907, test=0.901), total=   2.1s\n",
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.0min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.901, test=0.911), total=   2.2s\n",
            "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  2.1min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-07, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.912, test=0.890), total=   2.1s\n",
            "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  2.1min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.867, test=0.864), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:  2.2min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.868, test=0.864), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:  2.3min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000002e-08, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.873, test=0.866), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  2.4min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.845, test=0.842), total=   3.1s\n",
            "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:  2.4min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.850, test=0.850), total=   3.0s\n",
            "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:  2.5min remaining:    0.0s\n",
            "[CV] C=1000, gamma=1.0000000000000003e-09, kernel=rbf ................\n",
            "[CV]  C=1000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.852, test=0.849), total=   2.9s\n",
            "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  2.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.971), total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  2.6min remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.953), total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.7min remaining:    0.0s\n",
            "[CV] C=10000, gamma=0.0001, kernel=rbf ...............................\n",
            "[CV]  C=10000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.976), total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:  2.7min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=1.000, test=0.978), total=   1.0s\n",
            "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:  2.7min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=1.000, test=0.982), total=   1.1s\n",
            "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:  2.8min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1e-05, kernel=rbf ................................\n",
            "[CV]  C=10000, gamma=1e-05, kernel=rbf, score=(train=1.000, test=0.983), total=   1.0s\n",
            "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  2.8min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.998, test=0.978), total=   1.2s\n",
            "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:  2.8min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.995, test=0.986), total=   1.2s\n",
            "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:  2.8min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-06, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=0.996, test=0.986), total=   1.1s\n",
            "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:  2.9min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.967, test=0.964), total=   1.6s\n",
            "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:  2.9min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.961, test=0.958), total=   1.7s\n",
            "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:  3.0min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-07, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.969, test=0.947), total=   1.6s\n",
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.0min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.907, test=0.896), total=   2.2s\n",
            "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:  3.1min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.899, test=0.910), total=   2.2s\n",
            "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:  3.1min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000002e-08, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.911, test=0.893), total=   2.2s\n",
            "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:  3.2min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.867, test=0.864), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  3.2min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.867, test=0.865), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  3.3min remaining:    0.0s\n",
            "[CV] C=10000, gamma=1.0000000000000003e-09, kernel=rbf ...............\n",
            "[CV]  C=10000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.873, test=0.863), total=   2.7s\n",
            "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:  3.4min remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.971), total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:  3.4min remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.953), total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:  3.5min remaining:    0.0s\n",
            "[CV] C=100000, gamma=0.0001, kernel=rbf ..............................\n",
            "[CV]  C=100000, gamma=0.0001, kernel=rbf, score=(train=1.000, test=0.976), total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:  3.5min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=1.000, test=0.978), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  3.5min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=1.000, test=0.975), total=   1.0s\n",
            "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:  3.5min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1e-05, kernel=rbf ...............................\n",
            "[CV]  C=100000, gamma=1e-05, kernel=rbf, score=(train=1.000, test=0.978), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  3.6min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=1.000, test=0.978), total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:  3.6min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=1.000, test=0.986), total=   1.0s\n",
            "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:  3.6min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-06, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-06, kernel=rbf, score=(train=1.000, test=0.983), total=   1.0s\n",
            "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  3.6min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.998, test=0.982), total=   1.1s\n",
            "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:  3.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.995, test=0.988), total=   1.2s\n",
            "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:  3.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-07, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-07, kernel=rbf, score=(train=0.996, test=0.986), total=   1.1s\n",
            "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:  3.7min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.965, test=0.965), total=   1.6s\n",
            "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:  3.8min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.960, test=0.958), total=   1.7s\n",
            "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  3.8min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000002e-08, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000002e-08, kernel=rbf, score=(train=0.968, test=0.946), total=   1.6s\n",
            "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:  3.9min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.907, test=0.896), total=   2.2s\n",
            "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:  3.9min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.899, test=0.909), total=   2.2s\n",
            "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:  4.0min remaining:    0.0s\n",
            "[CV] C=100000, gamma=1.0000000000000003e-09, kernel=rbf ..............\n",
            "[CV]  C=100000, gamma=1.0000000000000003e-09, kernel=rbf, score=(train=0.910, test=0.893), total=   2.1s\n",
            "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:  4.0min remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:  4.0min finished\n",
            "{'C': 0.1, 'kernel': 'linear'}\n",
            "1000 features  Spam precision: 0.8402777777777778\n",
            "1000 features  Spam recall 0.8419243986254296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lCsuHK-uFC3",
        "outputId": "bcca1069-1b0a-45dc-e420-d15f96e00176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Adversarial Classification\n",
        "#Bernoulli NB classifier with binary features\n",
        "#for each file in training text, feature is found =1, feature not found =0\n",
        "'''\n",
        "for m in range (0, 1):\n",
        " X_train =[]\n",
        " y_train =[]\n",
        " X_test = []\n",
        " y_test = []\n",
        " for x in range(0,len(training_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_train.append(int(training_dataset[x][3]))\n",
        "   wordsbag = training_dataset[x][2].split()\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "     if feature_array[m][y] in wordsbag:\n",
        "       row[y] = 1 \n",
        "   X_train.append(row)\n",
        " \n",
        " #for each file in training text, feature is found =1, feature not found =0\n",
        " for x in range(0,len(testing_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_test.append(int(testing_dataset[x][3]))\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "     if feature_array[m][y] in testing_dataset[x][2]:\n",
        "       row[y] = 1 \n",
        "   X_test.append(row)\n",
        "   \n",
        "\n",
        " from sklearn.naive_bayes import BernoulliNB\n",
        " from sklearn.model_selection import train_test_split\n",
        " from sklearn import metrics\n",
        " from sklearn.metrics import confusion_matrix\n",
        " # Create three binary features\n",
        " X = X_train\n",
        " # Create a binary target vector\n",
        " y = y_train\n",
        " # View first ten observations\n",
        " \n",
        " # Create Bernoulli Naive Bayes object with prior probabilities of each class\n",
        " clf = BernoulliNB(class_prior=[0.25, 0.5])\n",
        " \n",
        " # Train model\n",
        " model = clf.fit(X, y)\n",
        " #print(len(clf.predict(X_test)))\n",
        " #print(len(y_test))\n",
        " tn, fp, fn, tp = confusion_matrix(y_test,model.predict(X_test)).ravel()\n",
        " #false negative rate\n",
        " print(len(feature_array[m]),'features ','false negative rate before ad. modify:',fn/(fn+tp))\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 features  false negative rate before ad. modify: 0.01652892561983471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79yo3TzWejo9",
        "outputId": "0c81e60f-cdc5-4d93-b972-77af30ea9f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#spam number given x\n",
        "#calculation W(gapx) for each feature word\n",
        "gapx_array = []\n",
        "nenenenen = []\n",
        "for y in range (len(gain_result)-10,len(gain_result)):\n",
        " x_length = 0\n",
        " spam_num_x = 0\n",
        " legit_num_x = 0\n",
        " for x in range(0,len(training_dataset)):\n",
        "  \n",
        "   #split sentence into bag of words first, then do the comparsion\n",
        "   words = training_dataset[x][2].split()\n",
        "   if gain_result[y][1] in words:\n",
        "    x_length = x_length + 1 \n",
        "    if training_dataset[x][3] == '1':\n",
        "     spam_num_x = spam_num_x + 1\n",
        "     #print('found in spam: ',training_dataset[x][3])\n",
        "    else :\n",
        "      legit_num_x = legit_num_x + 1  \n",
        "      #print('found in legit',training_dataset[x][3])\n",
        " print(x_length,spam_num_x,legit_num_x)\n",
        "\n",
        " nenenenen = gain_result[y]\n",
        " nenenenen.append((spam_num_x/legit_num_x)-1)\n",
        " nenenenen = list(dict.fromkeys(nenenenen))\n",
        " gapx_array.append(nenenenen)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "627 260 367\n",
            "173 132 41\n",
            "1671 107 1564\n",
            "129 116 13\n",
            "227 169 58\n",
            "1293 17 1276\n",
            "1105 0 1105\n",
            "380 251 129\n",
            "207 185 22\n",
            "1454 7 1447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js8Na2H3PDEz",
        "outputId": "d8f94bec-0552-469a-9881-cef4ceebb80b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "#P(xi|+) = how many spam email contains word feature\n",
        "#P(xi|-) = how many legit email contains word feature\n",
        "\n",
        "for y in range (0,len(gapx_array)):\n",
        " legit_num_x = 0\n",
        " spam_num_x = 0\n",
        " for x in range(0,len(training_dataset)):  \n",
        "   #split sentence into bag of words first, then do the comparsion\n",
        "   words = training_dataset[x][2].split()\n",
        "   if gapx_array[y][1] in words:\n",
        "    if training_dataset[x][3] == '1':\n",
        "     spam_num_x = spam_num_x + 1\n",
        "     #print('found in spam: ',training_dataset[x][3])\n",
        "    else :\n",
        "      legit_num_x = legit_num_x + 1  \n",
        "      #print('found in legit',training_dataset[x][3])\n",
        " print(spam_num_x,legit_num_x)\n",
        "\n",
        "\n",
        " #we define lcox -> locxi as 0 -> 1 (good word appear) to overcome the 'bad' word influence\n",
        " try:\n",
        "  locx = log2((432 - spam_num_x)/(2170-legit_num_x)/432*2170)\n",
        " except:\n",
        "  locx = log2((432 - spam_num_x+1)/(2170-legit_num_x+2)/432*2170)\n",
        " try:\n",
        "  locxi= log2(spam_num_x/legit_num_x/432*2170)\n",
        " except:\n",
        "  locxi= log2((spam_num_x+1)/(legit_num_x+2)/432*2170)\n",
        "\n",
        " delta_loc = locx - locxi \n",
        "\n",
        "\n",
        " gapx_array[y].append(delta_loc)\n",
        "#total spam email number in training: 432 total legit email number in training 2170\n",
        "#total training email number: 2602 total testing email number: 291\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "260 367\n",
            "132 41\n",
            "107 1564\n",
            "116 13\n",
            "169 58\n",
            "17 1276\n",
            "0 1105\n",
            "251 129\n",
            "185 22\n",
            "7 1447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdSP_TR5W61J",
        "outputId": "e35a136f-9bad-484b-a9be-e35d6f3e100a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#explain each element in gapx_ array:\n",
        "#0 = IG value\n",
        "#1 = word feature\\\n",
        "#2 = gap(x) value P(+|x)/P(-|x) - 1 \n",
        "#3 = delta Loc = Loc(x) - Loc(x') ， we only consider postive value here, since negative value meaning switching the term does not help \n",
        "for x in range (0,len(gapx_array)):\n",
        "  print(gapx_array[x])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0.08879', 'our', -0.29155313351498635, -2.8926504869154854]\n",
            "['0.09251', 'market', 2.2195121951219514, -4.513983658696782]\n",
            "['0.09418', '@', -0.9315856777493606, 2.970679735349072]\n",
            "['0.10117', 'click', 7.923076923076923, -5.928570989969831]\n",
            "['0.11868', 'money', 1.9137931034482758, -4.548373571220764]\n",
            "['0.14501', 'university', -0.9866771159874608, 5.122786277565499]\n",
            "['0.14515', 'linguistic', -1.0, 8.810689293831821]\n",
            "['0.16573', 'free', 0.945736434108527, -4.455530878477032]\n",
            "['0.16891', 'remove', 7.409090909090908, -6.192360888279749]\n",
            "['0.20444', 'language', -0.995162404975812, 6.924961478548067]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jDYNz97hn4c"
      },
      "source": [
        "\n",
        "##Adversarial STRATEGY\n",
        "#MCC(x) is the nearest instance (costwise) to x which naive Bayes classifies as negative\n",
        "\n",
        "#Since top-10 features all has positive IG value, we do not have to check if delta Loc >=0\n",
        "\n",
        "\n",
        "'''\n",
        "x = 8\n",
        "w = gapx_array[x][2]    \n",
        "find_MCC(x,w)\n",
        "print(MinCost,MinList)\n",
        "\n",
        "def find_MCC(x,w):\n",
        "  # loop through n = (0,9)\n",
        " if w <= 0:\n",
        "  return 0,[]\n",
        " if x == 0:\n",
        "   return 100000, None\n",
        "\n",
        " MinCost = 100000 \n",
        " MinList =  []\n",
        "\n",
        " #for x in range (0,7):\n",
        " print(gapx_array[x])\n",
        " if gapx_array[x][3] >=0:\n",
        "    CurCost, CurList = find_MCC(x-1,float(w)-float(gapx_array[x][3]))\n",
        "    CurCost = CurCost + 1\n",
        "    List_adding = []\n",
        "    List_adding.append(gapx_array[x][1])\n",
        "    List_adding.append(x)\n",
        "    CurList = List_adding\n",
        "\n",
        "    if CurCost < MinCost:     \n",
        "      MinCost = CurCost      \n",
        "      MinList = CurList\n",
        "      #print(MinCost,MinList)\n",
        " return MinCost, MinList\n",
        " \n",
        "'''\n",
        "#more efficient way to find the optimal solution for each feature word that gapx > 0 \n",
        "filter_postive = []\n",
        "for x in range (0,len(gapx_array)):\n",
        " if gapx_array[x][2] > 0:\n",
        "   filter_postive.append(gapx_array[x])\n",
        "\n",
        "\n",
        "filter_negative = []\n",
        "for x in range (0,len(gapx_array)):\n",
        " if gapx_array[x][3] >= 0:\n",
        "   #print(gapx_array[x])\n",
        "   filter_negative.append(gapx_array[x])\n",
        "\n",
        "\n",
        "\n",
        "filter_negative.sort(reverse=True,key=lambda x: x[3])\n",
        "\n",
        "\n",
        "total_gap = []\n",
        "total_word = []\n",
        "import itertools\n",
        "for L in range(0, len(filter_postive)+1):\n",
        "  #get all the combinations of words that gap(x) is larger than 0 \n",
        "    for subset in itertools.combinations(filter_postive, L):\n",
        "      if len(subset) > 0:\n",
        "       # print(subset)\n",
        "        count = 0\n",
        "        word_count = []\n",
        "        for z in range(0,len(subset)):\n",
        "          count = count + subset[z][2]\n",
        "          word_count.append(subset[z][1])\n",
        "        total_gap.append(count)\n",
        "        total_word.append(word_count)\n",
        "filter_postive.sort(reverse=True,key=lambda x: x[2])\n",
        "\n",
        "final_gap_word_count = []\n",
        "for x in range (0,len(total_gap)):\n",
        "  temp = []\n",
        "  temp.append(total_word[x])\n",
        "  \n",
        "  n = 0\n",
        "  mins_count = filter_negative[n][3]\n",
        "  while total_gap[x] - mins_count > 0:\n",
        "    n = n +1\n",
        "    mins_count= mins_count + filter_negative[n][3]\n",
        "  temp.append(n+1)\n",
        "  #final_gap_count store all the combination of 'spam' word and how many 'legit' word (sorted in a descending order) need to add to make w < 0\n",
        "  final_gap_word_count.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2nm2aR1-yxC",
        "outputId": "23c67ac1-b665-4b80-f7c4-b3fbc73c54a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "for x in range (0,len(final_gap_word_count)):\n",
        "  print(final_gap_word_count[x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['market'], 1]\n",
            "[['click'], 1]\n",
            "[['money'], 1]\n",
            "[['free'], 1]\n",
            "[['remove'], 1]\n",
            "[['market', 'click'], 2]\n",
            "[['market', 'money'], 1]\n",
            "[['market', 'free'], 1]\n",
            "[['market', 'remove'], 2]\n",
            "[['click', 'money'], 2]\n",
            "[['click', 'free'], 2]\n",
            "[['click', 'remove'], 2]\n",
            "[['money', 'free'], 1]\n",
            "[['money', 'remove'], 2]\n",
            "[['free', 'remove'], 1]\n",
            "[['market', 'click', 'money'], 2]\n",
            "[['market', 'click', 'free'], 2]\n",
            "[['market', 'click', 'remove'], 3]\n",
            "[['market', 'money', 'free'], 1]\n",
            "[['market', 'money', 'remove'], 2]\n",
            "[['market', 'free', 'remove'], 2]\n",
            "[['click', 'money', 'free'], 2]\n",
            "[['click', 'money', 'remove'], 3]\n",
            "[['click', 'free', 'remove'], 3]\n",
            "[['money', 'free', 'remove'], 2]\n",
            "[['market', 'click', 'money', 'free'], 2]\n",
            "[['market', 'click', 'money', 'remove'], 3]\n",
            "[['market', 'click', 'free', 'remove'], 3]\n",
            "[['market', 'money', 'free', 'remove'], 2]\n",
            "[['click', 'money', 'free', 'remove'], 3]\n",
            "[['market', 'click', 'money', 'free', 'remove'], 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl0g2GCXMPzN"
      },
      "source": [
        "From above result, it shows any combinations of 'bad' words in 10 features, and the number(also represent for the cost) represents how many 'good' words has to be add, accroding to good words in a descending order, to make this email being legit to classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBLFOlzy0f2U"
      },
      "source": [
        "#I replace the recursive function with another approach that will reduce the running time, here is my explaination:\n",
        "# firstly, I made 2 arrays from 10 features. One array, which called filter_postive store the features that gap(x),w > 0.\n",
        "#Second array called filter_negative that store features that has positive ∆LOi value. Then sorting the second array in descending order, thus, we can do what inside the recursive function:(w − ∆LOi) and get the minimum result list when w < 0 in the fastest way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYxEJR1cVs9r",
        "outputId": "ed52ddff-71da-4b9d-d6d1-d9a58f235944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Add word to testing dataset to see if it works\n",
        "\n",
        "for m in range (0, 1):\n",
        " X_train =[]\n",
        " y_train =[]\n",
        " X_test = []\n",
        " y_test = []\n",
        " for x in range(0,len(training_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_train.append(int(training_dataset[x][3]))\n",
        "   wordsbag = training_dataset[x][2].split()\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "     if feature_array[m][y] in wordsbag:\n",
        "       row[y] = 1 \n",
        "   X_train.append(row)\n",
        " \n",
        " #for each file in training text, feature is found =1, feature not found =0\n",
        " for x in range(0,len(testing_dataset)): \n",
        "   row = [0] * len(feature_array[m])\n",
        "   y_test.append(int(testing_dataset[x][3]))\n",
        "   wordsbag = testing_dataset[x][2].split()\n",
        "   for y in range (0,len(feature_array[m])):    \n",
        "     if feature_array[m][y] in wordsbag:\n",
        "       row[y] = 1 \n",
        "\n",
        "   \n",
        "   X_test.append(row)\n",
        "   \n",
        "\n",
        " from sklearn.naive_bayes import BernoulliNB\n",
        " from sklearn.model_selection import train_test_split\n",
        " from sklearn import metrics\n",
        " from sklearn.metrics import confusion_matrix\n",
        " # Create three binary features\n",
        " X = X_train\n",
        " # Create a binary target vector\n",
        " y = y_train\n",
        " # View first ten observations\n",
        " \n",
        " # Create Bernoulli Naive Bayes object with prior probabilities of each class\n",
        " clf = BernoulliNB(class_prior=[0.25, 0.5])\n",
        " \n",
        " # Train model\n",
        " model = clf.fit(X, y)\n",
        " #print(len(clf.predict(X_test)))\n",
        " #print(len(y_test))\n",
        " tn, fp, fn, tp = confusion_matrix(y_test,model.predict(X_test)).ravel()\n",
        " #false negative rate\n",
        " print(len(feature_array[m]),'features ','false negative rate BEFORE ad. modify:',fn/(fn+tp))\n",
        " print(len(feature_array[m]),'features ','Spam recall',clf.score(X_test, y_test))\n",
        " #print(len(feature_array[m]),'features ','false positive rate Before ad. modify:',fp/(fp+tn))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 features  false negative rate BEFORE ad. modify: 0.04081632653061224\n",
            "10 features  Spam recall 0.9518900343642611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB3KPc7doCrm",
        "outputId": "c360197f-de8d-41a0-c0eb-96e4660556f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "new_X_test = X_test\n",
        "y_pred = clf.predict(X_test)\n",
        "#print(len(y_pred),len(new_X_test))\n",
        "last_cost_result = []\n",
        "final_gap_word_count.sort(reverse=True,key=lambda x: len(x[0]))\n",
        "\n",
        "for x in range (0,len(testing_dataset)):\n",
        " if y_pred[x] == 1 :\n",
        "  wordsbag  =  testing_dataset[x][2].split()\n",
        "  for y in range (0,(len(final_gap_word_count))):\n",
        "    if set(final_gap_word_count[y][0]).issubset(set(wordsbag)) == True:\n",
        "      newsdsfdsf = []\n",
        "      newsdsfdsf.append(final_gap_word_count[y])\n",
        "      newsdsfdsf.append(x)\n",
        "      last_cost_result.append(newsdsfdsf)\n",
        "      break\n",
        "  \n",
        "last_cost_result.sort(reverse=True,key=lambda x: x[1])\n",
        "an_iterator = itertools.groupby(last_cost_result, lambda x : x[1]) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "p_count = 0\n",
        "#algo. 2\n",
        "#since we already knew the feature word 'linguistic' has largest delta Loc value\n",
        "# and this feature word can overcome any feature words that w > 0 with cost 1 \n",
        "# therefore, following the algo. #2, we add this 'linguistic' to any email if NB(x) = +\n",
        "\n",
        "'''\n",
        "for x in range (0,len(new_X_test)):\n",
        "  if y_pred[x] == 1:\n",
        "    new_X_test[x][6] = 1\n",
        "    new_X_test[x][9] = 1\n",
        "    new_X_test[x][5] = 1\n",
        "'''\n",
        "\n",
        "#index 6 for each row in X_test is the position for word 'linguistic' (largest impact)\n",
        "#index 9 for each row in X_test is the position for word 'language' (second largest impact)\n",
        "#index 5 for each row in X_test is the position for word 'university'(third largest impact)\n",
        "\n",
        "cost = 0\n",
        "total_spam_count = 0\n",
        "for x in range (0,len(last_cost_result)):\n",
        "  if last_cost_result[x][0][1] == 1:\n",
        "    new_X_test[last_cost_result[x][1]][6] = 1   \n",
        "    cost = cost + 1 \n",
        "    total_spam_count = total_spam_count + 1 \n",
        "  elif last_cost_result[x][0][1] == 2:\n",
        "    new_X_test[last_cost_result[x][1]][6] = 1\n",
        "    new_X_test[last_cost_result[x][1]][9] = 1\n",
        "    cost = cost + 2 \n",
        "    total_spam_count = total_spam_count + 1 \n",
        "  elif last_cost_result[x][0][1] == 3:\n",
        "    new_X_test[last_cost_result[x][1]][6] = 1\n",
        "    new_X_test[last_cost_result[x][1]][9] = 1\n",
        "    new_X_test[last_cost_result[x][1]][5] = 1\n",
        "    cost = cost + 3\n",
        "    total_spam_count = total_spam_count + 1 \n",
        "\n",
        "\n",
        "second_part = []\n",
        "for x in range(0,len(last_cost_result)):\n",
        "  second_part.append(last_cost_result[x][1])\n",
        "\n",
        "\n",
        "#somehow ther is a few email still classified as spam even after adding the 'largest impact word', so I treat those email individually.\n",
        "# and final accuray increased after adding 3 'impact words'\n",
        "new_y_pred = clf.predict(new_X_test)\n",
        "for x in range (0,len(new_y_pred)):\n",
        "  if new_y_pred[x] == 1 :\n",
        "    new_X_test[x][6] = 1\n",
        "    new_X_test[x][9] = 1\n",
        "    new_X_test[x][5] = 1\n",
        "    cost = cost + 3\n",
        "    for y in range (0,len(last_cost_result)):\n",
        "      if x == last_cost_result[y][1]:\n",
        "        #when we treating those speical email (those still classified as spam even after adding the 'largest impact word'), we do not want the cost be calculated twice, therefore, we have to minus the orginal cost that we added in the previous part\n",
        "        cost = cost - last_cost_result[y][0][1]\n",
        "       \n",
        "    total_spam_count = total_spam_count + 1\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "print('average cost over all email: ',cost/total_spam_count)\n",
        "\n",
        "print('accuracy recall after adversary strategy:', clf.score(new_X_test, y_test))\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,clf.predict(new_X_test)).ravel()\n",
        "#print(fn, tp, tn, fp)\n",
        "print(len(feature_array[m]),'features ','false negative rate AFTER ad. modify:',fn/(fn+tp))\n",
        "#print(len(feature_array[m]),'features ','false positive rate AFTER ad. modify:',tp/(tp+fn))\n",
        "#from here, we found the false positive rate is 0, which means all the spam was falsely predicated as positive\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average cost over all email:  1.7272727272727273\n",
            "accuracy recall after adversary strategy: 0.8419243986254296\n",
            "10 features  false negative rate AFTER ad. modify: 0.9387755102040817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79YsywEr-uey"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxhNRmOWbbRJ",
        "outputId": "4eb52d22-28fb-4ee4-d40b-fa3170d8ac6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#CLASSIFIER STRATEGY\n",
        "#for all negative prediction, using a greedy approach, let's minus its total_gap(x) from the largest gap(x) value word, and store how many words were removed\n",
        "y_new_pred = clf.predict(new_X_test)\n",
        "final_y_pred = y_new_pred\n",
        "gap_value = []\n",
        "y_new_pred = clf.predict(new_X_test)\n",
        "for y in range (0,len(new_X_test)):\n",
        "  gap_value_count = 0\n",
        "  if y_new_pred[y] == 0:  \n",
        "    for x in range (0,len(new_X_test[y])):\n",
        "      if new_X_test[y][x] == 1:\n",
        "        gap_value_count = gap_value_count + gapx_array[x][2]\n",
        "  gap_value.append(gap_value_count)\n",
        "  #print(gap_value_count,y_new_pred[y],y_test[y])\n",
        "\n",
        "\n",
        "for x in range (0,len(gap_value)):\n",
        "  #bad_key_word_count = 0 \n",
        " # good_key_word_count= 0\n",
        "  if y_new_pred[x] == 0:\n",
        "    if new_X_test[x][6] == 1 :\n",
        "    #  good_key_word_count = good_key_word_count + 1\n",
        "      if gap_value[x] >= 0 :\n",
        "        final_y_pred[x] = 1\n",
        "  #print(gap_value[x],final_y_pred[x],y_test[x])\n",
        "\n",
        "for x in range(0,len(new_X_test)):\n",
        "  bad_key_word_count = 0 \n",
        "  good_key_word_count= 0\n",
        "\n",
        "  if new_X_test[x][6] == 1 :\n",
        "      good_key_word_count = good_key_word_count + 1 \n",
        "  if new_X_test[x][9] == 1 :\n",
        "      good_key_word_count = good_key_word_count + 1 \n",
        "  if new_X_test[x][1] == 1:\n",
        "      bad_key_word_count = bad_key_word_count + 1\n",
        "  if new_X_test[x][3] == 1:\n",
        "      bad_key_word_count = bad_key_word_count + 1\n",
        "  if new_X_test[x][8] == 1:\n",
        "      bad_key_word_count = bad_key_word_count + 1\n",
        "  if new_X_test[x][4] == 1:\n",
        "      bad_key_word_count = bad_key_word_count + 1\n",
        "  if bad_key_word_count >= 2 :\n",
        "    final_y_pred[x] ==1\n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy after classifier response',accuracy_score(y_test, final_y_pred))\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,final_y_pred).ravel()\n",
        "print(len(feature_array[m]),'features ','false negative rate AFTER ad. modify:',fn/(fn+tp))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy after classifier response 0.9037800687285223\n",
            "10 features  false negative rate AFTER ad. modify: 0.3673469387755102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL_kiUNY6JAr",
        "outputId": "4f8de55a-1ef5-4726-cc8e-e567307e596a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "'''\n",
        "for x in range(0,len(new_X_test)):\n",
        "  bad_key_word_count = 0 \n",
        "  bad_key_word_value = 0\n",
        "  good_key_word_count= 0\n",
        "  good_key_word_value = 0\n",
        "\n",
        "  if new_X_test[x][6] == 1 :\n",
        "      good_key_word_count = good_key_word_count + 1 \n",
        "      good_key_word_value = good_key_word_value + gapx_array[6][3]\n",
        "  if new_X_test[x][9] == 1 :\n",
        "      good_key_word_count = good_key_word_count + 1 \n",
        "      good_key_word_value = good_key_word_value + gapx_array[9][3]\n",
        "  if new_X_test[x][1] == 1:\n",
        "      bad_key_word_count = bad_key_word_count + 1\n",
        "      bad_key_word_value = bad_key_word_value + gapx_array[1][2]\n",
        "  if new_X_test[x][3] == 1:\n",
        "      bad_key_word_count = bad_key_word_count + 1\n",
        "      bad_key_word_value = bad_key_word_value + gapx_array[3][2]\n",
        "  if new_X_test[x][8] == 1:\n",
        "      bad_key_word_count = bad_key_word_count + 1\n",
        "      bad_key_word_value = bad_key_word_value + gapx_array[8][2]\n",
        "  if new_X_test[x][4] == 1:\n",
        "      bad_key_word_count = bad_key_word_count + 1\n",
        "      bad_key_word_value = bad_key_word_value + gapx_array[4][2]\n",
        "  print('bad:',bad_key_word_count,'good:',good_key_word_count,'pred:',final_y_pred[x],'acutal:',y_test[x],bad_key_word_value,good_key_word_value)   \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfor x in range(0,len(new_X_test)):\\n  bad_key_word_count = 0 \\n  bad_key_word_value = 0\\n  good_key_word_count= 0\\n  good_key_word_value = 0\\n\\n  if new_X_test[x][6] == 1 :\\n      good_key_word_count = good_key_word_count + 1 \\n      good_key_word_value = good_key_word_value + gapx_array[6][3]\\n  if new_X_test[x][9] == 1 :\\n      good_key_word_count = good_key_word_count + 1 \\n      good_key_word_value = good_key_word_value + gapx_array[9][3]\\n  if new_X_test[x][1] == 1:\\n      bad_key_word_count = bad_key_word_count + 1\\n      bad_key_word_value = bad_key_word_value + gapx_array[1][2]\\n  if new_X_test[x][3] == 1:\\n      bad_key_word_count = bad_key_word_count + 1\\n      bad_key_word_value = bad_key_word_value + gapx_array[3][2]\\n  if new_X_test[x][8] == 1:\\n      bad_key_word_count = bad_key_word_count + 1\\n      bad_key_word_value = bad_key_word_value + gapx_array[8][2]\\n  if new_X_test[x][4] == 1:\\n      bad_key_word_count = bad_key_word_count + 1\\n      bad_key_word_value = bad_key_word_value + gapx_array[4][2]\\n  print('bad:',bad_key_word_count,'good:',good_key_word_count,'pred:',final_y_pred[x],'acutal:',y_test[x],bad_key_word_value,good_key_word_value)   \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAcAFqGLaodu"
      },
      "source": [
        "Final Report:\n",
        "\n",
        "1.Top-10 words from IG result:\n",
        "\n",
        "  ['0.08879', 'our']<br>\n",
        "  ['0.09251', 'market']<br>\n",
        "  ['0.09418', '@']<br>\n",
        "  ['0.10117', 'click']<br>\n",
        "  ['0.11868', 'money']<br>\n",
        "  ['0.14501', 'university']<br>\n",
        "  ['0.14515', 'linguistic']<br>\n",
        "  ['0.16573', 'free']<br>\n",
        "  ['0.16891', 'remove']<br>\n",
        "  ['0.20444', 'language']<br>\n",
        "\n",
        "\n",
        "<br>2. 9 rows:<br>\n",
        "NB classifier with binary features 10 features  Spam precision: 0.9869565217391304<br>\n",
        "NB classifier with binary features 10 features  Spam recall 0.9381443298969072<br>\n",
        "NB classifier with binary features 100 features  Spam precision: 0.9714285714285714<br>\n",
        "NB classifier with binary features 100 features  Spam recall 0.9621993127147767<br>\n",
        "NB classifier with binary features 1000 features  Spam precision: 0.944<br>\n",
        "NB classifier with binary features 1000 features  Spam recall 0.9381443298969072<br>\n",
        "<br>\n",
        "Multinomial NB with binary features 10 features  Spam precision: 0.9598393574297188<br>\n",
        "Multinomial NB with binary features 10 features  Spam recall 0.9553264604810997<br>\n",
        "Multinomial NB with binary features 100 features  Spam precision: 0.9836734693877551<br>\n",
        "Multinomial NB with binary features 100 features  Spam recall 0.9828178694158075<br>\n",
        "Multinomial NB with binary features 1000 features  Spam precision: 0.9758064516129032<br>\n",
        "Multinomial NB with binary features 1000 features  Spam recall 0.979381443298969<br>\n",
        "<br>\n",
        "Multi TF: 10 features  Spam precision: 0.9871794871794872<br>\n",
        "Multi TF: 10 features  Spam recall 0.9518900343642611<br>\n",
        "Multi TF: 100 features  Spam precision: 0.9795918367346939<br>\n",
        "Multi TF: 100 features  Spam recall 0.9759450171821306<br>\n",
        "Multi TF: 1000 features  Spam precision: 0.8515901060070671<br>\n",
        "Multi TF: 1000 features  Spam recall 0.852233676975945<br>\n",
        "\n",
        "3.SVM<br>\n",
        "From SVM, I tested top10,top100,top1000 features<br>\n",
        "I used grid search to do the cross-vaildation for the parameters tuning. for each top feature set, there are 84 sets for hyper-parameters combinations. You can find the detail of how I design the grid serach at SVM code cell<br>\n",
        " #feature 10\n",
        "{'C': 100000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
        "10 features  Spam precision: 0.9512195121951219\n",
        "10 features  Spam recall 0.9312714776632303\n",
        "\n",
        " #feature100\n",
        "{'C': 0.1, 'kernel': 'linear'}<br>\n",
        "100 features  Spam precision: 0.9696969696969697<br>\n",
        "100 features  Spam recall 0.9140893470790378<br>\n",
        " #feature1000\n",
        "{'C': 0.1, 'kernel': 'linear'}<br>\n",
        "1000 features  Spam precision: 0.8402777777777778<br>\n",
        "1000 features  Spam recall 0.8419243986254296<br>\n",
        "<br>\n",
        "4.Adversarial Classification under NB classifier with binary<br>\n",
        "Before attack:<br>\n",
        "10 features  false negative rate BEFORE ad. modify: 0.04081632653061224<br>\n",
        "10 features  Spam recall 0.9518900343642611<br>\n",
        "\n",
        "After attack:<br>\n",
        "average cost over all spam email:  1.7272727272727273<br>\n",
        "accuracy recall after adversary strategy: 0.8419243986254296<br>\n",
        "10 features  false negative rate AFTER ad. modify: 0.9387755102040817<br>\n",
        "\n",
        "After classifer response:<br>\n",
        "accuracy after classifier response 0.9037800687285223<br>\n",
        "10 features  false negative rate AFTER ad. modify: 0.3673469387755102<>\n",
        "\n"
      ]
    }
  ]
}